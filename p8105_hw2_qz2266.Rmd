---
title: "p8105_hw2_qz2266"
author: "Qing Zhou"
date: "2022-10-05"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r libraries}
library(tidyverse)
library(readxl)
```

# Problem 2

## Read and clean the Mr. Trash Wheel sheet.

```{r}
mr_trash_wheel = 
  read_excel("data/Trash Wheel Collection data-new.xlsx", 
  sheet = "Mr. Trash Wheel", 
  range =  cell_cols("A:N"), skip = 1) %>% 
  
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls = as.integer(round(sports_balls, digits = 0)),year = as.integer(year))
  
```

## Read and clean the Professor Trash Wheel sheet.

```{r}
prof_trash_wheel = 
  read_excel("data/Trash Wheel Collection data-new.xlsx", 
  sheet = "Professor Trash Wheel", 
  range =  cell_cols("A:M"), skip = 1) %>% 
  
  janitor::clean_names() %>% 
  drop_na(dumpster) 
```

## Add a new variable to keep track of which Trash Wheel is which.

```{r}
mr_trash_wheel_new = mutate(mr_trash_wheel, trash_wheel_type = "Mr.") %>%
                     relocate(trash_wheel_type, .before = dumpster) 
                     
prof_trash_wheel_new = mutate(prof_trash_wheel, trash_wheel_type = "Prof.") %>% 
                       relocate(trash_wheel_type, .before = dumpster) 
```                       

## Combine two datasets

```{r}
trash_wheel = 
  bind_rows(mr_trash_wheel_new, prof_trash_wheel_new)
```

## Data discription

The original mr_trash_wheel data set has `r ncol(mr_trash_wheel)` variables, including `r colnames(mr_trash_wheel)`, and `r nrow(mr_trash_wheel)` observations. 
The original prof_trash_wheel data set has `r ncol(prof_trash_wheel)` variables, including `r colnames(prof_trash_wheel)`, and `r nrow(prof_trash_wheel)` observations. 
As for the combined data set, there are `r ncol(trash_wheel)` variables, and `r nrow(trash_wheel)` observations. Key variables are measurements of trash collected, including weight,volume and trash type, such as plastic bottles, cigarette butts, grocery bags -- in addition to the date of the collection.


The total weight of trash collected by Professor Trash Wheel is `r round(sum(pull(prof_trash_wheel, weight_tons), na.rm = TRUE))` tons. Similarly, if we use the combined data set, it would be `r round(sum(pull(filter(trash_wheel, trash_wheel_type == 'Prof.'),  weight_tons), na.rm = TRUE))` tons.


The total number of sports balls collected by Mr. Trash Wheel in 2020 is `r round(sum(pull(filter(mr_trash_wheel, year == 2020), sports_balls), na.rm = TRUE))`. If we use the combined data set, the number is the same. It is `r round(sum(pull(filter(trash_wheel, trash_wheel_type == 'Mr.' & year == 2020),  sports_balls), na.rm = TRUE))`.


# Problem 3

## Clean the data in pols-month.csv.

```{r read_pols_month}
pols = read_csv("data/fivethirtyeight_datasets/fivethirtyeight_datasets/pols-month.csv") %>%
  janitor::clean_names() %>%
  
  separate(col = mon, into = c("year", "month", "day")) %>%
  mutate(
    year = as.integer(year), 
    day = as.integer(day),
    month = month.name[as.integer(month)]) %>%
  
  mutate(president = recode(prez_dem, `1` = "dem", `0` = "gop")) %>%
  select(-prez_gop, -prez_dem, -day)
```

## Clean the data in snp.csv.

```{r read_snp}

library(lubridate)

snp = read_csv("data/fivethirtyeight_datasets/fivethirtyeight_datasets/snp.csv") %>%
  janitor::clean_names() %>%
  
  mutate(date = lubridate::parse_date_time2(date, orders = "mdy", cutoff_2000 = 23)) %>%
  separate(col = date, into = c("year", "month", "day")) %>%
  mutate(
    year = as.integer(year), 
    day = as.integer(day)) %>%
  arrange(year, month) %>%
  mutate(month = month.name[as.integer(month)]) %>%
  
  select(year, month, day, close)
```

## Clean the data in unemployment.csv.

 
```{r read_unemployment}
unemp =
  read_csv("data/fivethirtyeight_datasets/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemp_rate"
  ) %>%
  mutate(month = match(month, month.abb)) %>%
  mutate(month = month.name[month]) %>%
  janitor::clean_names() %>%
  mutate(year = as.integer(year))
```

## Merge the data sets

```{r merge}
snp_pols_merge = 
  left_join(pols, snp, by = c("year","month")) %>%
  relocate(year, month, day)

merge_538 = 
  left_join(snp_pols_merge, unemp, by = c("year","month"))
  
```

## Dpescription of the dataset

The pols-month dataset describes the political landscape of the US, such as the number of politicians who are democratic or republican at the presidential, governor, and senate level on the associated date. It has  `r ncol(pols)` variables, including `r colnames(pols)`, and `r nrow(pols)` observations, from `r min(pull(pols, year))` to `r max(pull(pols, year))`.


The snp dataset describes the closing vales of the S&P stock index on the associated date. It has  `r ncol(snp)` variables, including `r colnames(snp)`, and `r nrow(snp)` observations, from `r min(pull(snp, year))` to `r max(pull(snp, year))`.


The unemployment data set introduces the percentage of unemployment rate in each month of the associated year. It has  `r ncol(unemp)` variables, including `r colnames(unemp)`, and `r nrow(unemp)` observations, from `r min(pull(unemp, year))` to `r max(pull(unemp, year))`.


The final dataset merge_538 combines the previous 3 datasets together, by year and month, creating a large dataset that contains information on the political landscape, stock performance, and unemployment rate from `r min(pull(merge_538, year))` to `r max(pull(merge_538, year))`. This final dataset dimensions are  `r nrow(merge_538)` rows and `r ncol(merge_538)` columns, including `r colnames(merge_538)`.


One key variable in this dataset is the **president** variable. It indicates whether the president on the associated date was republican or democratic. This variable could be used to evaluate the performance of the president, when considering other variables.


# Problem 1

Data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv` was imported and cleaned. Firstly we use read_csv to import data set, then we update variable names, and selects the useful variables. We also convert `entry` from `yes` / `no` to a logical variable. Moreover, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
trans_ent = 
  read_csv(
    "data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(
    line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
trans_ent %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
trans_ent %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
trans_ent %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct

trans_ent %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```